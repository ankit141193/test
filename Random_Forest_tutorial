{
  "paragraphs": [
    {
      "text": "%md\n\n# Introduction\nspark.ml is a new package introduced in Spark 1.2, which aims to provide a uniform set of high-level APIs that help users create and tune practical machine learning pipelines. This tutorial will explore SparkML in detail. Our tutorial will cover both an unsupervised and supervised machine learning algorithm from the sparkML library. To better demonstrate the power of Spark and AWS, the project will demonstrate customer segmentation of an airline dataset. To demonstrate the power of Spark and AWS, the project will demonstrate customer segmentation of an airline dataset and also look at analyzing emails to classify spam messages.\n\n## Supervised Learning\nBinary classification is a supervised learning problem in which we want to classify entities into one of two distinct categories or labels. This problem involves executing a learning Algorithm on a set of labeled examples, that is , a set of entities represented via features along with underlying category labels. The algorithm returns a trained Model that can predict the label for new entities for which the underlying label is unknown. \nTo demonstrate binary classification, we are using data XYZ Corportation which is a International conglomerate operating in many domains and geographies. XYZ employees receive thousands of emails on a daily basis. As an improved security measure XYZ would like implement a custom spam filter for its employee emails and classifiy the received mails into spam and not spam.\n\n\n",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512317885993_-709138261",
      "id": "20171203-161805_901565336",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003espark.ml is a new package introduced in Spark 1.2, which aims to provide a uniform set of high-level APIs that help users create and tune practical machine learning pipelines. This tutorial will explore SparkML in detail. Our tutorial will cover both an unsupervised and supervised machine learning algorithm from the sparkML library. To better demonstrate the power of Spark and AWS, the project will demonstrate customer segmentation of an airline dataset. To demonstrate the power of Spark and AWS, the project will demonstrate customer segmentation of an airline dataset and also look at analyzing emails to classify spam messages.\u003c/p\u003e\n\u003ch2\u003eSupervised Learning\u003c/h2\u003e\n\u003cp\u003eBinary classification is a supervised learning problem in which we want to classify entities into one of two distinct categories or labels. This problem involves executing a learning Algorithm on a set of labeled examples, that is , a set of entities represented via features along with underlying category labels. The algorithm returns a trained Model that can predict the label for new entities for which the underlying label is unknown.\u003cbr/\u003eTo demonstrate binary classification, we are using data XYZ Corportation which is a International conglomerate operating in many domains and geographies. XYZ employees receive thousands of emails on a daily basis. As an improved security measure XYZ would like implement a custom spam filter for its employee emails and classifiy the received mails into spam and not spam.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:18:05 PM",
      "dateStarted": "Dec 3, 2017 6:22:44 PM",
      "dateFinished": "Dec 3, 2017 6:22:44 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## Load and Explore Data\nFirst of all, we will load the csv file which has the labeled data. The data has 57 columns and 4601 rows, where the last column is the label. A label value of 1 signifies that the mail is a spam while a value of 0 signifies its not a spam.\n\nData Source: https://archive.ics.uci.edu/ml/datasets/spambase",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:43:12 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512318712852_1750135669",
      "id": "20171203-163152_1865085562",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eLoad and Explore Data\u003c/h2\u003e\n\u003cp\u003eFirst of all, we will load the csv file which has the labeled data. The data has 57 columns and 4601 rows, where the last column is the label. A label value of 1 signifies that the mail is a spam while a value of 0 signifies its not a spam.\u003c/p\u003e\n\u003cp\u003eData Source: \u003ca href\u003d\"https://archive.ics.uci.edu/ml/datasets/spambase\"\u003ehttps://archive.ics.uci.edu/ml/datasets/spambase\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:31:52 PM",
      "dateStarted": "Dec 3, 2017 6:43:12 PM",
      "dateFinished": "Dec 3, 2017 6:43:12 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "data \u003d sqlContext.read.format(\u0027com.databricks.spark.csv\u0027) \\\r\n    .option(\"inferSchema\",True).option(\"header\",True).load(\"s3://s3-ankit/Spam_data/HW4_DATA.csv\")",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511743782053_1259988708",
      "id": "20171127-004942_655764443",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": ""
      },
      "dateCreated": "Nov 27, 2017 12:49:42 AM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nFor easy reading, we can convert the dataframe to Pandas dataframe and display the first three rows.",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512319489816_-1635179079",
      "id": "20171203-164449_109940522",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eFor easy reading, we can convert the dataframe to Pandas dataframe and display the first three rows.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:44:49 PM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "data.limit(3).toPandas()",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512318400338_1318636227",
      "id": "20171203-162640_1119034163",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n0            0.00               0.64           0.64             0   \n1            0.21               0.28           0.50             0   \n2            0.06               0.00           0.71             0   \n\n   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n0           0.32            0.00              0.00                0.00   \n1           0.14            0.28              0.21                0.07   \n2           1.23            0.19              0.19                0.12   \n\n   word_freq_order  word_freq_mail     ...       char_freq_;  char_freq_(  \\\n0             0.00            0.00     ...              0.00        0.000   \n1             0.00            0.94     ...              0.00        0.132   \n2             0.64            0.25     ...              0.01        0.143   \n\n   char_freq_[  char_freq_!  char_freq_$  char_freq_#  \\\n0          0.0        0.778        0.000        0.000   \n1          0.0        0.372        0.180        0.048   \n2          0.0        0.276        0.184        0.010   \n\n   capital_run_length_avera  capital_run_length_longe  \\\n0                     3.756                        61   \n1                     5.114                       101   \n2                     9.821                       485   \n\n   capital_run_length_total  spam_nospam  \n0                       278            1  \n1                      1028            1  \n2                      2259            1  \n\n[3 rows x 58 columns]\n"
      },
      "dateCreated": "Dec 3, 2017 4:26:40 PM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nTo view the schema of the dataframe, we can use printSchema(). This operation displays the schema as a visual tree.",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512319563969_254630898",
      "id": "20171203-164603_1173119743",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eTo view the schema of the dataframe, we can use printSchema(). This operation displays the schema as a visual tree.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:46:03 PM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "data.printSchema()",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511743921312_1439448617",
      "id": "20171127-005201_2078475149",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- word_freq_make: double (nullable \u003d true)\n |-- word_freq_address: double (nullable \u003d true)\n |-- word_freq_all: double (nullable \u003d true)\n |-- word_freq_3d: integer (nullable \u003d true)\n |-- word_freq_our: double (nullable \u003d true)\n |-- word_freq_over: double (nullable \u003d true)\n |-- word_freq_remove: double (nullable \u003d true)\n |-- word_freq_internet: double (nullable \u003d true)\n |-- word_freq_order: double (nullable \u003d true)\n |-- word_freq_mail: double (nullable \u003d true)\n |-- word_freq_receive: double (nullable \u003d true)\n |-- word_freq_will: double (nullable \u003d true)\n |-- word_freq_people: double (nullable \u003d true)\n |-- word_freq_report: double (nullable \u003d true)\n |-- word_freq_addresses: double (nullable \u003d true)\n |-- word_freq_free: double (nullable \u003d true)\n |-- word_freq_business: double (nullable \u003d true)\n |-- word_freq_email: double (nullable \u003d true)\n |-- word_freq_you: double (nullable \u003d true)\n |-- word_freq_credit: double (nullable \u003d true)\n |-- word_freq_your: double (nullable \u003d true)\n |-- word_freq_font: double (nullable \u003d true)\n |-- word_freq_000: double (nullable \u003d true)\n |-- word_freq_money: double (nullable \u003d true)\n |-- word_freq_hp: double (nullable \u003d true)\n |-- word_freq_hpl: double (nullable \u003d true)\n |-- word_freq_george: integer (nullable \u003d true)\n |-- word_freq_650: double (nullable \u003d true)\n |-- word_freq_lab: double (nullable \u003d true)\n |-- word_freq_labs: integer (nullable \u003d true)\n |-- word_freq_telnet: double (nullable \u003d true)\n |-- word_freq_857: integer (nullable \u003d true)\n |-- word_freq_data: double (nullable \u003d true)\n |-- word_freq_415: double (nullable \u003d true)\n |-- word_freq_85: double (nullable \u003d true)\n |-- word_freq_technology: double (nullable \u003d true)\n |-- word_freq_1999: double (nullable \u003d true)\n |-- word_freq_parts: double (nullable \u003d true)\n |-- word_freq_pm: double (nullable \u003d true)\n |-- word_freq_direct: double (nullable \u003d true)\n |-- word_freq_cs: integer (nullable \u003d true)\n |-- word_freq_meeting: double (nullable \u003d true)\n |-- word_freq_original: double (nullable \u003d true)\n |-- word_freq_project: double (nullable \u003d true)\n |-- word_freq_re: double (nullable \u003d true)\n |-- word_freq_edu: double (nullable \u003d true)\n |-- word_freq_table: integer (nullable \u003d true)\n |-- word_freq_conference: double (nullable \u003d true)\n |-- char_freq_;: double (nullable \u003d true)\n |-- char_freq_(: double (nullable \u003d true)\n |-- char_freq_[: double (nullable \u003d true)\n |-- char_freq_!: double (nullable \u003d true)\n |-- char_freq_$: double (nullable \u003d true)\n |-- char_freq_#: double (nullable \u003d true)\n |-- capital_run_length_avera: double (nullable \u003d true)\n |-- capital_run_length_longe: integer (nullable \u003d true)\n |-- capital_run_length_total: integer (nullable \u003d true)\n |-- spam_nospam: integer (nullable \u003d true)\n\n"
      },
      "dateCreated": "Nov 27, 2017 12:52:01 AM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nFor binary classification, we need to convert the labeled column to \u0027double\u0027 as the model expects it to be double. To do this we use cast(). ",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512319610112_922631609",
      "id": "20171203-164650_437152326",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eFor binary classification, we need to convert the labeled column to \u0026lsquo;double\u0026rsquo; as the model expects it to be double. To do this we use cast().\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:46:50 PM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "#converting all the columns into double\n\nfrom pyspark.sql.functions import col\ndf \u003d data.select([col(c).cast(\"double\") for c in data.columns])\ndf.printSchema()",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511743953166_1058794037",
      "id": "20171127-005233_656269205",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- word_freq_make: double (nullable \u003d true)\n |-- word_freq_address: double (nullable \u003d true)\n |-- word_freq_all: double (nullable \u003d true)\n |-- word_freq_3d: double (nullable \u003d true)\n |-- word_freq_our: double (nullable \u003d true)\n |-- word_freq_over: double (nullable \u003d true)\n |-- word_freq_remove: double (nullable \u003d true)\n |-- word_freq_internet: double (nullable \u003d true)\n |-- word_freq_order: double (nullable \u003d true)\n |-- word_freq_mail: double (nullable \u003d true)\n |-- word_freq_receive: double (nullable \u003d true)\n |-- word_freq_will: double (nullable \u003d true)\n |-- word_freq_people: double (nullable \u003d true)\n |-- word_freq_report: double (nullable \u003d true)\n |-- word_freq_addresses: double (nullable \u003d true)\n |-- word_freq_free: double (nullable \u003d true)\n |-- word_freq_business: double (nullable \u003d true)\n |-- word_freq_email: double (nullable \u003d true)\n |-- word_freq_you: double (nullable \u003d true)\n |-- word_freq_credit: double (nullable \u003d true)\n |-- word_freq_your: double (nullable \u003d true)\n |-- word_freq_font: double (nullable \u003d true)\n |-- word_freq_000: double (nullable \u003d true)\n |-- word_freq_money: double (nullable \u003d true)\n |-- word_freq_hp: double (nullable \u003d true)\n |-- word_freq_hpl: double (nullable \u003d true)\n |-- word_freq_george: double (nullable \u003d true)\n |-- word_freq_650: double (nullable \u003d true)\n |-- word_freq_lab: double (nullable \u003d true)\n |-- word_freq_labs: double (nullable \u003d true)\n |-- word_freq_telnet: double (nullable \u003d true)\n |-- word_freq_857: double (nullable \u003d true)\n |-- word_freq_data: double (nullable \u003d true)\n |-- word_freq_415: double (nullable \u003d true)\n |-- word_freq_85: double (nullable \u003d true)\n |-- word_freq_technology: double (nullable \u003d true)\n |-- word_freq_1999: double (nullable \u003d true)\n |-- word_freq_parts: double (nullable \u003d true)\n |-- word_freq_pm: double (nullable \u003d true)\n |-- word_freq_direct: double (nullable \u003d true)\n |-- word_freq_cs: double (nullable \u003d true)\n |-- word_freq_meeting: double (nullable \u003d true)\n |-- word_freq_original: double (nullable \u003d true)\n |-- word_freq_project: double (nullable \u003d true)\n |-- word_freq_re: double (nullable \u003d true)\n |-- word_freq_edu: double (nullable \u003d true)\n |-- word_freq_table: double (nullable \u003d true)\n |-- word_freq_conference: double (nullable \u003d true)\n |-- char_freq_;: double (nullable \u003d true)\n |-- char_freq_(: double (nullable \u003d true)\n |-- char_freq_[: double (nullable \u003d true)\n |-- char_freq_!: double (nullable \u003d true)\n |-- char_freq_$: double (nullable \u003d true)\n |-- char_freq_#: double (nullable \u003d true)\n |-- capital_run_length_avera: double (nullable \u003d true)\n |-- capital_run_length_longe: double (nullable \u003d true)\n |-- capital_run_length_total: double (nullable \u003d true)\n |-- spam_nospam: double (nullable \u003d true)\n\n"
      },
      "dateCreated": "Nov 27, 2017 12:52:33 AM",
      "dateStarted": "Dec 3, 2017 5:41:15 PM",
      "dateFinished": "Dec 3, 2017 5:41:15 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## Train Test Split\nNext, we split the data into training and testing set. The training set is data on which our model will be trained, while the testing set is holdout data on which we test the performance of our trained model. The training set will comprise of 70% of the data and the rest 30% will be the testing/holdout data.",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:29 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512319810575_875367147",
      "id": "20171203-165010_578750726",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eTrain Test Split\u003c/h2\u003e\n\u003cp\u003eNext, we split the data into training and testing set. The training set is data on which our model will be trained, while the testing set is holdout data on which we test the performance of our trained model. The training set will comprise of 70% of the data and the rest 30% will be the testing/holdout data.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:50:10 PM",
      "dateStarted": "Dec 3, 2017 5:41:14 PM",
      "dateFinished": "Dec 3, 2017 5:41:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\r\ntrain, test \u003d df.randomSplit([0.7, 0.3])\r\nprint \"We have %d training examples and %d test examples.\" % (train.count(), test.count())",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511744157372_-753683055",
      "id": "20171127-005557_295406198",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "We have 3233 training examples and 1368 test examples.\n"
      },
      "dateCreated": "Nov 27, 2017 12:55:57 AM",
      "dateStarted": "Dec 3, 2017 5:41:15 PM",
      "dateFinished": "Dec 3, 2017 5:41:16 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Formatting the Data\nWe need to format data to bring it in a format which is acceptable to the ML algorithms. \n\n### StringIndexer\nIt encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0. We convert the label column to a column of label indices.\n\n### VectorAssembler\nIt is a transformer that combines a given list of columns into a single vector column. We use it to combine all the raw features which we plan to use in our model(labeled column is excluded). It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like random forest. \n\n## Train the Model\n\nNext, we train the model using the RandomForestClassifier(). In this operation, we specify our labeled column(indexedLabel) and the features we plan to use. We also mention the number of trees that we want our model to train on( in our case it is 50).\n\nNext, we create a evaluator where we can specify the metric which we want to evaluate. in our case, we use \u0027accuracy\u0027.\n\n## Cross-Validation on our Model\n\nIn k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k-1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method is that all observations are used for both training and validation, and each observation is used for validation exactly once. This provides a check of robustness of our performance.\n\n## Pipeline\nMLlib can represent a workflow as a Pipeline, which consists of a sequence of PipelineStages (Transformers and Estimators) to be run in a specific order. A Pipeline is specified as a sequence of stages, and each stage is either a Transformer or an Estimator. These stages are run in order, and the input DataFrame is transformed as it passes through each stage. For Transformer stages, the transform() method is called on the DataFrame. For Estimator stages, the fit() method is called.\n\n\nIn the last, we fit the model and use the fitted model to make predictions on the test/holdout data.\n\n",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512320159464_-1194844091",
      "id": "20171203-165559_196279041",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eFormatting the Data\u003c/h2\u003e\n\u003cp\u003eWe need to format data to bring it in a format which is acceptable to the ML algorithms. \u003c/p\u003e\n\u003ch3\u003eStringIndexer\u003c/h3\u003e\n\u003cp\u003eIt encodes a string column of labels to a column of label indices. The indices are in [0, numLabels), ordered by label frequencies, so the most frequent label gets index 0. We convert the label column to a column of label indices.\u003c/p\u003e\n\u003ch3\u003eVectorAssembler\u003c/h3\u003e\n\u003cp\u003eIt is a transformer that combines a given list of columns into a single vector column. We use it to combine all the raw features which we plan to use in our model(labeled column is excluded). It is useful for combining raw features and features generated by different feature transformers into a single feature vector, in order to train ML models like random forest. \u003c/p\u003e\n\u003ch2\u003eTrain the Model\u003c/h2\u003e\n\u003cp\u003eNext, we train the model using the RandomForestClassifier(). In this operation, we specify our labeled column(indexedLabel) and the features we plan to use. We also mention the number of trees that we want our model to train on( in our case it is 50).\u003c/p\u003e\n\u003cp\u003eNext, we create a evaluator where we can specify the metric which we want to evaluate. in our case, we use \u0026lsquo;accuracy\u0026rsquo;.\u003c/p\u003e\n\u003ch2\u003eCross-Validation on our Model\u003c/h2\u003e\n\u003cp\u003eIn k-fold cross-validation, the original sample is randomly partitioned into k equal size subsamples. Of the k subsamples, a single subsample is retained as the validation data for testing the model, and the remaining k-1 subsamples are used as training data. The cross-validation process is then repeated k times (the folds), with each of the k subsamples used exactly once as the validation data. The k results from the folds can then be averaged (or otherwise combined) to produce a single estimation. The advantage of this method is that all observations are used for both training and validation, and each observation is used for validation exactly once. This provides a check of robustness of our performance.\u003c/p\u003e\n\u003ch2\u003ePipeline\u003c/h2\u003e\n\u003cp\u003eMLlib can represent a workflow as a Pipeline, which consists of a sequence of PipelineStages (Transformers and Estimators) to be run in a specific order. A Pipeline is specified as a sequence of stages, and each stage is either a Transformer or an Estimator. These stages are run in order, and the input DataFrame is transformed as it passes through each stage. For Transformer stages, the transform() method is called on the DataFrame. For Estimator stages, the fit() method is called.\u003c/p\u003e\n\u003cp\u003eIn the last, we fit the model and use the fitted model to make predictions on the test/holdout data.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 4:55:59 PM",
      "dateStarted": "Dec 3, 2017 5:57:37 PM",
      "dateFinished": "Dec 3, 2017 5:57:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "from pyspark.ml.feature import VectorAssembler, VectorIndexer, StringIndexer, IndexToString\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.ml.classification import RandomForestClassifier\r\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\nfrom pyspark.ml.regression import RandomForestRegressor\r\nfrom pyspark.ml.feature import VectorIndexer\r\nfrom pyspark.ml.evaluation import RegressionEvaluator\r\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\r\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\r\n\r\n\r\n# Fit on whole dataset to include all labels in index.\r\n\r\nlabelIndexer \u003d StringIndexer(inputCol\u003d\"spam_nospam\", outputCol\u003d\"indexedLabel\").fit(df)\r\n\r\n\r\n\r\n# exclude the label column and combine all the features to be used in a vector\r\n\r\nfeaturesCols \u003d df.columns\r\nfeaturesCols.remove(\u0027spam_nospam\u0027)\r\nvectorAssembler \u003d VectorAssembler(inputCols\u003dfeaturesCols, outputCol\u003d\"Features\")\r\n\r\n\r\n#training the model\r\n\r\nrf \u003d RandomForestClassifier(labelCol\u003d\"indexedLabel\", featuresCol\u003d\"Features\", numTrees\u003d50)\r\n\r\n\r\n# creating an evaluator for accuracy metric\r\n\r\nevaluator \u003d MulticlassClassificationEvaluator(labelCol\u003drf.getLabelCol(), predictionCol\u003drf.getPredictionCol(), metricName\u003d\"accuracy\")\r\n\r\n\r\n# 5- Fold Cross-Validation \r\n\r\nparamGrid \u003d ParamGridBuilder() \\\r\n  .addGrid(rf.maxDepth, [2, 5])\\\r\n  .build() # .addGrid(gbt.maxIter, [10, 100])\r\n\r\n# Declare the CrossValidator, which runs model tuning for us.\r\n\r\ncv \u003d CrossValidator(estimator\u003drf, evaluator\u003devaluator, estimatorParamMaps\u003dparamGrid, numFolds\u003d 5)\r\n\r\n\r\n# Convert indexed labels back to original labels.\r\nlabelConverter \u003d IndexToString(inputCol\u003d\"prediction\", outputCol\u003d\"predictedLabel\", labels\u003dlabelIndexer.labels)\r\n\r\n\r\n# Chain indexers, cross-validator and forest in a Pipeline\r\n\r\npipeline \u003d Pipeline(stages\u003d[labelIndexer, vectorAssembler, cv, labelConverter])\r\n\r\n\r\n# Fit the model.  This also runs the indexers.\r\n\r\nmodel \u003d pipeline.fit(train)\r\n\r\n\r\n # Make predictions.\r\n \r\npredictions \u003d model.transform(test)\r\npredictions.printSchema()\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511744281040_-1536846281",
      "id": "20171127-005801_912693581",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "root\n |-- word_freq_make: double (nullable \u003d true)\n |-- word_freq_address: double (nullable \u003d true)\n |-- word_freq_all: double (nullable \u003d true)\n |-- word_freq_3d: double (nullable \u003d true)\n |-- word_freq_our: double (nullable \u003d true)\n |-- word_freq_over: double (nullable \u003d true)\n |-- word_freq_remove: double (nullable \u003d true)\n |-- word_freq_internet: double (nullable \u003d true)\n |-- word_freq_order: double (nullable \u003d true)\n |-- word_freq_mail: double (nullable \u003d true)\n |-- word_freq_receive: double (nullable \u003d true)\n |-- word_freq_will: double (nullable \u003d true)\n |-- word_freq_people: double (nullable \u003d true)\n |-- word_freq_report: double (nullable \u003d true)\n |-- word_freq_addresses: double (nullable \u003d true)\n |-- word_freq_free: double (nullable \u003d true)\n |-- word_freq_business: double (nullable \u003d true)\n |-- word_freq_email: double (nullable \u003d true)\n |-- word_freq_you: double (nullable \u003d true)\n |-- word_freq_credit: double (nullable \u003d true)\n |-- word_freq_your: double (nullable \u003d true)\n |-- word_freq_font: double (nullable \u003d true)\n |-- word_freq_000: double (nullable \u003d true)\n |-- word_freq_money: double (nullable \u003d true)\n |-- word_freq_hp: double (nullable \u003d true)\n |-- word_freq_hpl: double (nullable \u003d true)\n |-- word_freq_george: double (nullable \u003d true)\n |-- word_freq_650: double (nullable \u003d true)\n |-- word_freq_lab: double (nullable \u003d true)\n |-- word_freq_labs: double (nullable \u003d true)\n |-- word_freq_telnet: double (nullable \u003d true)\n |-- word_freq_857: double (nullable \u003d true)\n |-- word_freq_data: double (nullable \u003d true)\n |-- word_freq_415: double (nullable \u003d true)\n |-- word_freq_85: double (nullable \u003d true)\n |-- word_freq_technology: double (nullable \u003d true)\n |-- word_freq_1999: double (nullable \u003d true)\n |-- word_freq_parts: double (nullable \u003d true)\n |-- word_freq_pm: double (nullable \u003d true)\n |-- word_freq_direct: double (nullable \u003d true)\n |-- word_freq_cs: double (nullable \u003d true)\n |-- word_freq_meeting: double (nullable \u003d true)\n |-- word_freq_original: double (nullable \u003d true)\n |-- word_freq_project: double (nullable \u003d true)\n |-- word_freq_re: double (nullable \u003d true)\n |-- word_freq_edu: double (nullable \u003d true)\n |-- word_freq_table: double (nullable \u003d true)\n |-- word_freq_conference: double (nullable \u003d true)\n |-- char_freq_;: double (nullable \u003d true)\n |-- char_freq_(: double (nullable \u003d true)\n |-- char_freq_[: double (nullable \u003d true)\n |-- char_freq_!: double (nullable \u003d true)\n |-- char_freq_$: double (nullable \u003d true)\n |-- char_freq_#: double (nullable \u003d true)\n |-- capital_run_length_avera: double (nullable \u003d true)\n |-- capital_run_length_longe: double (nullable \u003d true)\n |-- capital_run_length_total: double (nullable \u003d true)\n |-- spam_nospam: double (nullable \u003d true)\n |-- indexedLabel: double (nullable \u003d true)\n |-- Features: vector (nullable \u003d true)\n |-- rawPrediction: vector (nullable \u003d true)\n |-- probability: vector (nullable \u003d true)\n |-- prediction: double (nullable \u003d true)\n |-- predictedLabel: string (nullable \u003d true)\n\n"
      },
      "dateCreated": "Nov 27, 2017 12:58:01 AM",
      "dateStarted": "Dec 3, 2017 5:52:33 PM",
      "dateFinished": "Dec 3, 2017 5:53:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\nWe can display the predictions and the features.",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512323933468_180257747",
      "id": "20171203-175853_1809658753",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eWe can display the predictions and the features.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 5:58:53 PM",
      "dateStarted": "Dec 3, 2017 5:59:26 PM",
      "dateFinished": "Dec 3, 2017 5:59:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": " # Select example rows to display.\r\n \r\npredictions.select(\"predictedLabel\", \"spam_nospam\", \"Features\").show(10)",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "tableHide": false,
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511747342843_2135070513",
      "id": "20171127-014902_540997814",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "+--------------+-----------+--------------------+\n|predictedLabel|spam_nospam|            Features|\n+--------------+-----------+--------------------+\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n|           0.0|        0.0|(57,[54,55,56],[1...|\n+--------------+-----------+--------------------+\nonly showing top 10 rows\n\n"
      },
      "dateCreated": "Nov 27, 2017 1:49:02 AM",
      "dateStarted": "Dec 3, 2017 6:13:11 PM",
      "dateFinished": "Dec 3, 2017 6:13:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md \n\n## Evaluating the Performance of the Model\n\nWe can evaluate the performance of our model on the following metric\n\n1\\. Accuracy - Ratio of correctly predicted observations.\n2\\. Precision - Precision looks at the ratio of correct positive observations. The formula is True Positives / (True Positives + False Positives).\n3\\. Recall - Recall is also known as sensitivity or true positive rate. It’s the ratio of correctly predicted positive events. Recall is calculated as True Positives / (True Positives + False Negatives).\n4\\. F1 measure - The F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. F1 is usually more useful than accuracy, especially if the class distribution is uneven.",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/markdown",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512323981121_-1519365323",
      "id": "20171203-175941_409702624",
      "result": {
        "code": "SUCCESS",
        "type": "HTML",
        "msg": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eEvaluating the Performance of the Model\u003c/h2\u003e\n\u003cp\u003eWe can evaluate the performance of our model on the following metric\u003c/p\u003e\n\u003cp\u003e1. Accuracy - Ratio of correctly predicted observations.\u003cbr/\u003e2. Precision - Precision looks at the ratio of correct positive observations. The formula is True Positives / (True Positives + False Positives).\u003cbr/\u003e3. Recall - Recall is also known as sensitivity or true positive rate. It’s the ratio of correctly predicted positive events. Recall is calculated as True Positives / (True Positives + False Negatives).\u003cbr/\u003e4. F1 measure - The F1 Score is the weighted average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account. F1 is usually more useful than accuracy, especially if the class distribution is uneven.\u003c/p\u003e\n\u003c/div\u003e"
      },
      "dateCreated": "Dec 3, 2017 5:59:41 PM",
      "dateStarted": "Dec 3, 2017 6:08:54 PM",
      "dateFinished": "Dec 3, 2017 6:08:54 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "accuracy \u003d evaluator.evaluate(predictions)\nprint(accuracy)",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512237866540_2112498411",
      "id": "20171202-180426_1258507384",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "0.926900584795\n"
      },
      "dateCreated": "Dec 2, 2017 6:04:26 PM",
      "dateStarted": "Dec 3, 2017 6:18:10 PM",
      "dateFinished": "Dec 3, 2017 6:18:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "predictions \u003d predictions.withColumn(\u0027predictedLabel\u0027,predictions.predictedLabel.cast(\u0027double\u0027))\nevaluator1 \u003d MulticlassClassificationEvaluator(labelCol\u003d\"indexedLabel\", predictionCol\u003d\"predictedLabel\", metricName\u003d\"weightedPrecision\")\nprecision \u003d evaluator1.evaluate(predictions)\nprint precision",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511745673037_766524730",
      "id": "20171127-012113_729636645",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "0.927923976608\n"
      },
      "dateCreated": "Nov 27, 2017 1:21:13 AM",
      "dateStarted": "Dec 3, 2017 6:18:13 PM",
      "dateFinished": "Dec 3, 2017 6:18:14 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "evaluator2 \u003d MulticlassClassificationEvaluator(labelCol\u003d\"indexedLabel\", predictionCol\u003d\"predictedLabel\", metricName\u003d\"weightedRecall\")\nrecall \u003d evaluator2.evaluate(predictions)\nprint recall",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1511811704361_-1723600636",
      "id": "20171127-194144_677019211",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "0.926900584795\n"
      },
      "dateCreated": "Nov 27, 2017 7:41:44 PM",
      "dateStarted": "Dec 3, 2017 6:19:07 PM",
      "dateFinished": "Dec 3, 2017 6:19:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "evaluator3 \u003d MulticlassClassificationEvaluator(labelCol\u003d\"indexedLabel\", predictionCol\u003d\"predictedLabel\", metricName\u003d\"f1\")\nf1 \u003d evaluator3.evaluate(predictions)\nprint(f1)",
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512241147787_1164545520",
      "id": "20171202-185907_73297337",
      "result": {
        "code": "SUCCESS",
        "type": "TEXT",
        "msg": "0.926175392184\n"
      },
      "dateCreated": "Dec 2, 2017 6:59:07 PM",
      "dateStarted": "Dec 3, 2017 6:18:25 PM",
      "dateFinished": "Dec 3, 2017 6:18:27 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "user": "pande130@umn.edu",
      "dateUpdated": "Dec 3, 2017 6:42:30 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "editorMode": "ace/mode/scala",
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512241184198_2082418478",
      "id": "20171202-185944_1934451651",
      "result": {
        "code": "ERROR",
        "type": "TEXT",
        "msg": "Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-7393478501326668276.py\", line 245, in \u003cmodule\u003e\n    stmts \u003d req.statements().split(\"\\n\")\nAttributeError: \u0027NoneType\u0027 object has no attribute \u0027split\u0027\n"
      },
      "dateCreated": "Dec 2, 2017 6:59:44 PM",
      "dateStarted": "Dec 3, 2017 5:42:01 PM",
      "dateFinished": "Dec 3, 2017 5:42:02 PM",
      "status": "ERROR",
      "progressUpdateIntervalMs": 500
    },
    {
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "jobName": "paragraph_1512410869145_499149114",
      "id": "20171204-180749_2039585089",
      "dateCreated": "Dec 4, 2017 6:07:49 PM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Random_Forest_tutorial",
  "id": "3GPWH12J2E1511742497",
  "angularObjects": {
    "2CZ66272U418151510596353934:shared_process": [],
    "2CX5JE1BP418151510596353942:shared_process": [],
    "2D1HGQUY3418151510596353907:shared_process": [],
    "2CZ4DUATT418151510596353928:shared_process": []
  },
  "config": {
    "isDashboard": false,
    "looknfeel": "default",
    "cronExecutingUser": "40460",
    "cron_updated_by_useremail": "pande130@umn.edu"
  },
  "info": {},
  "source": "FCN"
}